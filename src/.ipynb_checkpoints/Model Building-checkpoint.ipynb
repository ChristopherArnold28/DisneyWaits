{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "This notebook will go over the process of testing different variations of models to find the parameters that best suit the model for this application. \n",
    "\n",
    "* Model Type\n",
    "* Metric Evaluation\n",
    "* Hyper Parameter Tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from scipy.stats.stats import pearsonr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql\n",
    "import config\n",
    "import transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chrisA\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\chrisA\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\core\\indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "conn = pymysql.connect(config.host, user=config.username,port=config.port,\n",
    "                           passwd=config.password)\n",
    "\n",
    "#gather all historical data to build model\n",
    "RideWaits = pd.read_sql_query(\"call DisneyDB.RideWaitQuery\", conn)\n",
    "\n",
    "#transform data for model bulding\n",
    "RideWaits = transformations.transformData(RideWaits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RideId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Wait</th>\n",
       "      <th>Name</th>\n",
       "      <th>OpeningDate</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Location</th>\n",
       "      <th>IntellectualProp</th>\n",
       "      <th>Status</th>\n",
       "      <th>...</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>CharacterExperience</th>\n",
       "      <th>inEMH</th>\n",
       "      <th>validTime</th>\n",
       "      <th>EMHDay</th>\n",
       "      <th>TimeSinceOpen</th>\n",
       "      <th>TimeSinceMidday</th>\n",
       "      <th>MagicHourType</th>\n",
       "      <th>TimeSinceRideOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>35</td>\n",
       "      <td>Astro Orbiter</td>\n",
       "      <td>1995-02-25</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Tomorrowland</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>8472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>45</td>\n",
       "      <td>Big Thunder Mountain Railroad</td>\n",
       "      <td>1980-09-23</td>\n",
       "      <td>headliner</td>\n",
       "      <td>Frontierland</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>13740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>45</td>\n",
       "      <td>Buzz Lightyears Space Ranger Spin</td>\n",
       "      <td>1998-10-07</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Tomorrowland</td>\n",
       "      <td>Pixar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>40</td>\n",
       "      <td>Dumbo the Flying Elephant</td>\n",
       "      <td>1971-10-01</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Fantasyland</td>\n",
       "      <td>AnimatedClassic</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>17020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>25</td>\n",
       "      <td>Enchanted Tales with Belle</td>\n",
       "      <td>2012-12-06</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Fantasyland</td>\n",
       "      <td>AnimatedClassic</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RideId       Date      Time  Wait                               Name  \\\n",
       "0       0 2018-05-07  12:30:00    35                      Astro Orbiter   \n",
       "1       2 2018-05-07  12:30:00    45      Big Thunder Mountain Railroad   \n",
       "2       3 2018-05-07  12:30:00    45  Buzz Lightyears Space Ranger Spin   \n",
       "3       6 2018-05-07  12:30:00    40          Dumbo the Flying Elephant   \n",
       "4       7 2018-05-07  12:30:00    25         Enchanted Tales with Belle   \n",
       "\n",
       "  OpeningDate              Tier      Location IntellectualProp  Status  \\\n",
       "0  1995-02-25  minor_attraction  Tomorrowland             None       1   \n",
       "1  1980-09-23         headliner  Frontierland             None       1   \n",
       "2  1998-10-07  minor_attraction  Tomorrowland            Pixar       1   \n",
       "3  1971-10-01  minor_attraction   Fantasyland  AnimatedClassic       1   \n",
       "4  2012-12-06  minor_attraction   Fantasyland  AnimatedClassic       1   \n",
       "\n",
       "         ...         DayOfWeek  Weekend CharacterExperience  inEMH validTime  \\\n",
       "0        ...                 0        0                   0      0         1   \n",
       "1        ...                 0        0                   0      0         1   \n",
       "2        ...                 0        0                   0      0         1   \n",
       "3        ...                 0        0                   0      0         1   \n",
       "4        ...                 0        0                   0      0         1   \n",
       "\n",
       "  EMHDay TimeSinceOpen TimeSinceMidday MagicHourType TimeSinceRideOpen  \n",
       "0      1             3               2         Night              8472  \n",
       "1      1             3               2         Night             13740  \n",
       "2      1             3               2         Night              7152  \n",
       "3      1             3               2         Night             17020  \n",
       "4      1             3               2         Night              1978  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RideWaits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame looks quite different than in the prevsious exploratory analysis frame. Certain columns have been removed in an effort to consolidate and extract the vital information that has been seen to make a difference in Wait times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keyFeatures = [\"Name\",\"MagicHourType\", \"Tier\", \"IntellectualProp\", \"SimpleStatus\", \"ParkName\", \"DayOfWeek\", \"Weekend\", \"TimeSinceOpen\", \"CharacterExperience\", \"TimeSinceMidday\", \"inEMH\", \"EMHDay\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'MagicHourType',\n",
       " 'Tier',\n",
       " 'IntellectualProp',\n",
       " 'SimpleStatus',\n",
       " 'ParkName',\n",
       " 'DayOfWeek',\n",
       " 'Weekend',\n",
       " 'TimeSinceOpen',\n",
       " 'CharacterExperience',\n",
       " 'TimeSinceMidday',\n",
       " 'inEMH',\n",
       " 'EMHDay']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have established to this point that this list of features will cause the most impact on wait times and give the most insight into the dataset. \n",
    "These can be broken into categories into the information we are trying to gain:\n",
    "* Ride Characteristics\n",
    "    * Name\n",
    "    * Tier\n",
    "    * IntellectualProp (Intellectual Property)\n",
    "    * ParkName (Which park is this ride located in)\n",
    "    * CharacterExperience (Is this a character experience)\n",
    "* Time of Day Information\n",
    "    * DayOfWeek\n",
    "    * Weekend \n",
    "    * TimeSinceOpen (How many hours is it since the park opened that day)\n",
    "    * TimeSinceMidday (How many hours is it in absolute value since 2pm)\n",
    "    * inEMH (is this wait time in an Extra magic hour window)\n",
    "    * EMHDay (is this day at the park an Extra Magic Hour Day)\n",
    "    * MagicHourType (is this a extra magic morning or an extra magic night)\n",
    "* Weather\n",
    "    * SimpleStatus\n",
    "    \n",
    "As the dataset grows and the more months and weather characteristics pile in, this list of usable features may expand. For example, temperature is not being included in this list as all the data gathered as of today has been from one week, and the temperature pattern adds no value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryColumns = RideWaits.select_dtypes(include = ['category']).columns\n",
    "RideWaits[\"Name\"] = pd.Categorical(RideWaits[\"Name\"]).codes\n",
    "for col in categoryColumns:\n",
    "    RideWaits[col] = pd.Categorical(RideWaits[col]).codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25439 entries, 0 to 26238\n",
      "Data columns (total 13 columns):\n",
      "Name                   25439 non-null int8\n",
      "MagicHourType          25439 non-null int8\n",
      "Tier                   25439 non-null int8\n",
      "IntellectualProp       25439 non-null int8\n",
      "SimpleStatus           25439 non-null int8\n",
      "ParkName               25439 non-null int8\n",
      "DayOfWeek              25439 non-null int64\n",
      "Weekend                25439 non-null int64\n",
      "TimeSinceOpen          25439 non-null int64\n",
      "CharacterExperience    25439 non-null int64\n",
      "TimeSinceMidday        25439 non-null int64\n",
      "inEMH                  25439 non-null int64\n",
      "EMHDay                 25439 non-null int64\n",
      "dtypes: int64(7), int8(6)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "RideWaits[keyFeatures].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(RideWaits[keyFeatures], RideWaits[\"Wait\"], test_size = .25, random_state = 1)\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 1)\n",
    "rf.fit(train_x, train_y)\n",
    "predictions = rf.predict(test_x)\n",
    "rmseBase = metrics.mean_squared_error(predictions, test_y)**(1/2)\n",
    "r2Base = metrics.r2_score(predictions, test_y)\n",
    "varBase = metrics.explained_variance_score(predictions,test_y)\n",
    "pearsoncorrBase = pearsonr(predictions, test_y)\n",
    "perrorBase = abs(predictions - test_y)/test_y\n",
    "accuracyBase = 1 - statistics.median(perrorBase)\n",
    "errorBase = abs(predictions - test_y)\n",
    "merrorBase = errorBase.mean()\n",
    "medErrorBase = statistics.median(errorBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.028194219303769"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmseBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87167634408361439"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87167751949410999"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.939408125858892, 0.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsoncorrBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5866567852229121"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merrorBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medErrorBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the defaults of the Random forest regressor we can get some baseline statistics with this algorithm. We see we have a high correlation meaning that our predictions are following the proper trend of our data. Our accuracy for our base model is 87% and is not a bad start, we also see that both our mean and median wait time error values are under 10 minutes which is also a good place to start. We can now try some other modeling methods as well as tune the hyper parameters for our random forest model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with attempting to tune the hyper parameters for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our focus will be on the following parameters: \n",
    "* n_estimators\n",
    "* max_features\n",
    "* max_depth\n",
    "* min_samples_split\n",
    "* min_samples_leaf\n",
    "* bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10,110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,4]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfNew = RandomForestRegressor()\n",
    "rf_randomized = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose = 2, random_state = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 18.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomized.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 70,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 1800}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomized.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_random = rf_randomized.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = rf_random.predict(test_x)\n",
    "rmseRandom = metrics.mean_squared_error(predictions, test_y)**(1/2)\n",
    "r2Random = metrics.r2_score(predictions, test_y)\n",
    "varRandom = metrics.explained_variance_score(predictions,test_y)\n",
    "pearsoncorrRandom = pearsonr(predictions, test_y)\n",
    "perrorRandom = abs(predictions - test_y)/test_y\n",
    "accuracyRandom = 1 - statistics.median(perrorRandom)\n",
    "errorRandom = abs(predictions - test_y)\n",
    "merrorRandom = errorRandom.mean()\n",
    "medErroRandom = statistics.median(errorRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7205278867899914"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmseRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87692568282077343"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8769255514304688"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9434117447146374, 0.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsoncorrRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86243886901513289"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5176649027601119"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merrorRandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4209986464153177"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medErroRandom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a very slight increase in RMSE, mean error, and median Error, but see no increase in overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gridSearch = {'bootstrap': [True],\n",
    "              'max_depth' : [50,60,70,80,90],\n",
    "              'max_features': [6,7,8,9,10],\n",
    "              'min_samples_leaf': [1,2,3,4],\n",
    "              'n_estimators' : [200,300,500,1000,1500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestRegressor()\n",
    "grid_search_rf = GridSearchCV(estimator = rf, param_grid = gridSearch, cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 55.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 58.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': [50, 60, 70, 80, 90], 'max_features': [6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4], 'n_estimators': [200, 300, 500, 1000, 1500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 50,\n",
       " 'max_features': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_grid = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = best_grid.predict(test_x)\n",
    "rmseGrid = metrics.mean_squared_error(predictions, test_y)**(1/2)\n",
    "r2Grid = metrics.r2_score(predictions, test_y)\n",
    "varGrid = metrics.explained_variance_score(predictions,test_y)\n",
    "pearsoncorrGrid = pearsonr(predictions, test_y)\n",
    "perrorGrid = abs(predictions - test_y)/test_y\n",
    "accuracyGrid = 1 - statistics.median(perrorGrid)\n",
    "errorGrid = abs(predictions - test_y)\n",
    "merrorGrid = errorGrid.mean()\n",
    "medErrorGrid = statistics.median(errorGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.8481542038575434"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmseGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87499851414237972"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87499977527551553"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94174301332456123, 0.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsoncorrGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86451547619047664"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5206333879364511"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merrorGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3572023809523781"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medErrorGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight increase in accuracy but negligible effects across the board in most other categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
