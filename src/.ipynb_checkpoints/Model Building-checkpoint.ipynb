{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "This notebook will go over the process of testing different variations of models to find the parameters that best suit the model for this application. \n",
    "\n",
    "* Model Type\n",
    "* Metric Evaluation\n",
    "* Hyper Parameter Tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\chrisa\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from scipy.stats.stats import pearsonr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql\n",
    "import config\n",
    "import transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chrisA\\Documents\\DisneyWaitTimes\\DisneyWaits\\src\\transformations.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  RideWaits[\"MagicHourType\"] = pd.Categorical(RideWaits[\"MagicHourType\"])\n",
      "C:\\Users\\chrisA\\Documents\\DisneyWaitTimes\\DisneyWaits\\src\\transformations.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  RideWaits[\"TimeSinceRideOpen\"] = (RideWaits[\"Date\"] - RideWaits[\"OpeningDate\"]).dt.days\n"
     ]
    }
   ],
   "source": [
    "conn = pymysql.connect(config.host, user=config.username,port=config.port,\n",
    "                           passwd=config.password)\n",
    "\n",
    "#gather all historical data to build model\n",
    "RideWaits = pd.read_sql_query(\"call DisneyDB.RideWaitQuery\", conn)\n",
    "\n",
    "#transform data for model bulding\n",
    "RideWaits = transformations.transformData(RideWaits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RideId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Wait</th>\n",
       "      <th>Name</th>\n",
       "      <th>OpeningDate</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Location</th>\n",
       "      <th>IntellectualProp</th>\n",
       "      <th>Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>CharacterExperience</th>\n",
       "      <th>inEMH</th>\n",
       "      <th>validTime</th>\n",
       "      <th>EMHDay</th>\n",
       "      <th>TimeSinceOpen</th>\n",
       "      <th>TimeSinceMidday</th>\n",
       "      <th>MagicHourType</th>\n",
       "      <th>MinutesSinceOpen</th>\n",
       "      <th>TimeSinceRideOpen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>35</td>\n",
       "      <td>Astro Orbiter</td>\n",
       "      <td>1995-02-25</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Tomorrowland</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>210.0</td>\n",
       "      <td>8472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>45</td>\n",
       "      <td>Big Thunder Mountain Railroad</td>\n",
       "      <td>1980-09-23</td>\n",
       "      <td>headliner</td>\n",
       "      <td>Frontierland</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>210.0</td>\n",
       "      <td>13740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>45</td>\n",
       "      <td>Buzz Lightyears Space Ranger Spin</td>\n",
       "      <td>1998-10-07</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Tomorrowland</td>\n",
       "      <td>Pixar</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>210.0</td>\n",
       "      <td>7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>40</td>\n",
       "      <td>Dumbo the Flying Elephant</td>\n",
       "      <td>1971-10-01</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Fantasyland</td>\n",
       "      <td>AnimatedClassic</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>210.0</td>\n",
       "      <td>17020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>12:30:00</td>\n",
       "      <td>25</td>\n",
       "      <td>Enchanted Tales with Belle</td>\n",
       "      <td>2012-12-06</td>\n",
       "      <td>minor_attraction</td>\n",
       "      <td>Fantasyland</td>\n",
       "      <td>AnimatedClassic</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Night</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RideId       Date      Time  Wait                               Name  \\\n",
       "0       0 2018-05-07  12:30:00    35                      Astro Orbiter   \n",
       "1       2 2018-05-07  12:30:00    45      Big Thunder Mountain Railroad   \n",
       "2       3 2018-05-07  12:30:00    45  Buzz Lightyears Space Ranger Spin   \n",
       "3       6 2018-05-07  12:30:00    40          Dumbo the Flying Elephant   \n",
       "4       7 2018-05-07  12:30:00    25         Enchanted Tales with Belle   \n",
       "\n",
       "  OpeningDate              Tier      Location IntellectualProp  Status  \\\n",
       "0  1995-02-25  minor_attraction  Tomorrowland             None       1   \n",
       "1  1980-09-23         headliner  Frontierland             None       1   \n",
       "2  1998-10-07  minor_attraction  Tomorrowland            Pixar       1   \n",
       "3  1971-10-01  minor_attraction   Fantasyland  AnimatedClassic       1   \n",
       "4  2012-12-06  minor_attraction   Fantasyland  AnimatedClassic       1   \n",
       "\n",
       "         ...         Weekend  CharacterExperience inEMH  validTime EMHDay  \\\n",
       "0        ...               0                    0     0          1      1   \n",
       "1        ...               0                    0     0          1      1   \n",
       "2        ...               0                    0     0          1      1   \n",
       "3        ...               0                    0     0          1      1   \n",
       "4        ...               0                    0     0          1      1   \n",
       "\n",
       "  TimeSinceOpen TimeSinceMidday MagicHourType MinutesSinceOpen  \\\n",
       "0             3               2         Night            210.0   \n",
       "1             3               2         Night            210.0   \n",
       "2             3               2         Night            210.0   \n",
       "3             3               2         Night            210.0   \n",
       "4             3               2         Night            210.0   \n",
       "\n",
       "  TimeSinceRideOpen  \n",
       "0              8472  \n",
       "1             13740  \n",
       "2              7152  \n",
       "3             17020  \n",
       "4              1978  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RideWaits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame looks quite different than in the prevsious exploratory analysis frame. Certain columns have been removed in an effort to consolidate and extract the vital information that has been seen to make a difference in Wait times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyFeatures = [\"Name\",\"MagicHourType\", \"Tier\", \"IntellectualProp\", \"SimpleStatus\", \"ParkName\", \"DayOfWeek\", \"Weekend\", \"TimeSinceOpen\",\"MinutesSinceOpen\", \"CharacterExperience\", \"TimeSinceMidday\", \"inEMH\", \"EMHDay\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'MagicHourType',\n",
       " 'Tier',\n",
       " 'IntellectualProp',\n",
       " 'SimpleStatus',\n",
       " 'ParkName',\n",
       " 'DayOfWeek',\n",
       " 'Weekend',\n",
       " 'TimeSinceOpen',\n",
       " 'MinutesSinceOpen',\n",
       " 'CharacterExperience',\n",
       " 'TimeSinceMidday',\n",
       " 'inEMH',\n",
       " 'EMHDay']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have established to this point that this list of features will cause the most impact on wait times and give the most insight into the dataset. \n",
    "These can be broken into categories into the information we are trying to gain:\n",
    "* Ride Characteristics\n",
    "    * Name\n",
    "    * Tier\n",
    "    * IntellectualProp (Intellectual Property)\n",
    "    * ParkName (Which park is this ride located in)\n",
    "    * CharacterExperience (Is this a character experience)\n",
    "* Time of Day Information\n",
    "    * DayOfWeek\n",
    "    * Weekend \n",
    "    * TimeSinceOpen (How many hours is it since the park opened that day)\n",
    "    * TimeSinceMidday (How many hours is it in absolute value since 2pm)\n",
    "    * inEMH (is this wait time in an Extra magic hour window)\n",
    "    * EMHDay (is this day at the park an Extra Magic Hour Day)\n",
    "    * MagicHourType (is this a extra magic morning or an extra magic night)\n",
    "    * Minutes since park open. This and TimeSinceOpen may add unwanted variance. So I may remove TimeSinceOpen\n",
    "* Weather\n",
    "    * SimpleStatus\n",
    "    \n",
    "As the dataset grows and the more months and weather characteristics pile in, this list of usable features may expand. For example, temperature is not being included in this list as all the data gathered as of today has been from one week, and the temperature pattern adds no value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'MagicHourType', 'Tier', 'IntellectualProp', 'SimpleStatus', 'ParkName', 'DayOfWeek', 'Weekend', 'TimeSinceOpen', 'MinutesSinceOpen', 'CharacterExperience', 'TimeSinceMidday', 'inEMH', 'EMHDay', 'Wait']\n"
     ]
    }
   ],
   "source": [
    "keyFeatures.append(\"Wait\")\n",
    "RideWaits[\"Name\"] = pd.Categorical(RideWaits[\"Name\"])\n",
    "print(keyFeatures)\n",
    "RideWaits = RideWaits[keyFeatures]\n",
    "categoryColumns = RideWaits.select_dtypes(include = ['category']).columns\n",
    "for col in categoryColumns:\n",
    "    currentCategorical = pd.get_dummies(RideWaits[col], prefix = str(col+ \"_\"))\n",
    "    RideWaits = pd.concat([RideWaits,currentCategorical], axis = 1)\n",
    "    RideWaits = RideWaits.drop([col], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>TimeSinceOpen</th>\n",
       "      <th>MinutesSinceOpen</th>\n",
       "      <th>CharacterExperience</th>\n",
       "      <th>TimeSinceMidday</th>\n",
       "      <th>inEMH</th>\n",
       "      <th>EMHDay</th>\n",
       "      <th>Wait</th>\n",
       "      <th>Name__Astro Orbiter</th>\n",
       "      <th>...</th>\n",
       "      <th>SimpleStatus__Drizzle</th>\n",
       "      <th>SimpleStatus__Fog</th>\n",
       "      <th>SimpleStatus__Haze</th>\n",
       "      <th>SimpleStatus__Mist</th>\n",
       "      <th>SimpleStatus__Rain</th>\n",
       "      <th>SimpleStatus__Thunderstorm</th>\n",
       "      <th>ParkName__Animal Kingdom</th>\n",
       "      <th>ParkName__EpCot</th>\n",
       "      <th>ParkName__Hollywood Studios</th>\n",
       "      <th>ParkName__Magic Kingdom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DayOfWeek  Weekend  TimeSinceOpen  MinutesSinceOpen  CharacterExperience  \\\n",
       "0          0        0              3             210.0                    0   \n",
       "1          0        0              3             210.0                    0   \n",
       "2          0        0              3             210.0                    0   \n",
       "3          0        0              3             210.0                    0   \n",
       "4          0        0              3             210.0                    0   \n",
       "\n",
       "   TimeSinceMidday  inEMH  EMHDay  Wait  Name__Astro Orbiter  \\\n",
       "0                2      0       1    35                    1   \n",
       "1                2      0       1    45                    0   \n",
       "2                2      0       1    45                    0   \n",
       "3                2      0       1    40                    0   \n",
       "4                2      0       1    25                    0   \n",
       "\n",
       "            ...             SimpleStatus__Drizzle  SimpleStatus__Fog  \\\n",
       "0           ...                                 0                  0   \n",
       "1           ...                                 0                  0   \n",
       "2           ...                                 0                  0   \n",
       "3           ...                                 0                  0   \n",
       "4           ...                                 0                  0   \n",
       "\n",
       "   SimpleStatus__Haze  SimpleStatus__Mist  SimpleStatus__Rain  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   SimpleStatus__Thunderstorm  ParkName__Animal Kingdom  ParkName__EpCot  \\\n",
       "0                           0                         0                0   \n",
       "1                           0                         0                0   \n",
       "2                           0                         0                0   \n",
       "3                           0                         0                0   \n",
       "4                           0                         0                0   \n",
       "\n",
       "   ParkName__Hollywood Studios  ParkName__Magic Kingdom  \n",
       "0                            0                        1  \n",
       "1                            0                        1  \n",
       "2                            0                        1  \n",
       "3                            0                        1  \n",
       "4                            0                        1  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RideWaits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uint8      95\n",
       "int64       8\n",
       "float64     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RideWaits.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(RideWaits.drop(['Wait'], axis = 1), RideWaits[\"Wait\"], test_size = .25, random_state = 1)\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 1)\n",
    "rf.fit(train_x, train_y)\n",
    "predictions = rf.predict(test_x)\n",
    "rmseBase = metrics.mean_squared_error(predictions, test_y)**(1/2)\n",
    "r2Base = metrics.r2_score(predictions, test_y)\n",
    "varBase = metrics.explained_variance_score(predictions,test_y)\n",
    "pearsoncorrBase = pearsonr(predictions, test_y)\n",
    "perrorBase = abs(predictions - test_y)/test_y\n",
    "accuracyBase = 1 - statistics.median(perrorBase)\n",
    "errorBase = abs(predictions - test_y)\n",
    "merrorBase = errorBase.mean()\n",
    "medErrorBase = statistics.median(errorBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.923661523\n",
      "r2: 0.788478218211\n",
      "var:0.788489225161\n",
      "pearsonCorr: (0.90041281774326265, 0.0)\n",
      "Accuracy: 0.822752525253\n",
      "Mean Error: 7.40100001126\n",
      "Median Error: 4.5\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \" + str(rmseBase))\n",
    "print(\"r2: \"+ str(r2Base))\n",
    "print(\"var:\" + str(varBase))\n",
    "print(\"pearsonCorr: \"+ str(pearsoncorrBase))\n",
    "print(\"Accuracy: \" + str(accuracyBase))\n",
    "print(\"Mean Error: \" + str(merrorBase))\n",
    "print(\"Median Error: \" + str(medErrorBase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the defaults of the Random forest regressor we can get some baseline statistics with this algorithm. We see we have a high correlation meaning that our predictions are following the proper trend of our data. Our accuracy for our base model is 85% and is not a bad start, we also see that both our mean and median wait time error values are under 10 minutes which is also a good place to start. We can now try some other modeling methods as well as tune the hyper parameters for our random forest \n",
    "model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with attempting to tune the hyper parameters for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our focus will be on the following parameters: \n",
    "* n_estimators\n",
    "* max_features\n",
    "* max_depth\n",
    "* min_samples_split\n",
    "* min_samples_leaf\n",
    "* bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10,110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,4]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfNew = RandomForestRegressor()\n",
    "rf_randomized = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose = 2, random_state = 1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 55.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomized.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 70,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 1800}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomized.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = rf_randomized.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_random.predict(test_x)\n",
    "rmseRandom = metrics.mean_squared_error(predictions, test_y)**(1/2)\n",
    "r2Random = metrics.r2_score(predictions, test_y)\n",
    "varRandom = metrics.explained_variance_score(predictions,test_y)\n",
    "pearsoncorrRandom = pearsonr(predictions, test_y)\n",
    "perrorRandom = abs(predictions - test_y)/test_y\n",
    "accuracyRandom = 1 - statistics.median(perrorRandom)\n",
    "errorRandom = abs(predictions - test_y)\n",
    "merrorRandom = errorRandom.mean()\n",
    "medErrorRandom = statistics.median(errorRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.0204624125\n",
      "r2: 0.833626044924\n",
      "var:0.833628497388\n",
      "pearsonCorr: (0.92525807617302891, 0.0)\n",
      "Accuracy: 0.842966624205\n",
      "Mean Error: 6.16052199444\n",
      "Median Error: 3.64464177566\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \" + str(rmseRandom))\n",
    "print(\"r2: \"+ str(r2Random))\n",
    "print(\"var:\" + str(varRandom))\n",
    "print(\"pearsonCorr: \"+ str(pearsoncorrRandom))\n",
    "print(\"Accuracy: \" + str(accuracyRandom))\n",
    "print(\"Mean Error: \" + str(merrorRandom))\n",
    "print(\"Median Error: \" + str(medErrorRandom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a very slight increase in RMSE, mean error, and median Error, but see no increase in overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = {'bootstrap': [True],\n",
    "              'max_depth' : [60,70,80,90],\n",
    "              'max_features': ['auto',6,7,8,9,10],\n",
    "              'min_samples_leaf': [1,2,3,4],\n",
    "              'min_samples_split': [4,5,6,7],\n",
    "              'n_estimators' : [800,1200,1600,1800,2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestRegressor()\n",
    "grid_search_rf = GridSearchCV(estimator = rf, param_grid = gridSearch, cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1920 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 51.7min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 98.4min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 149.8min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 224.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 326.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 448.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 574.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 742.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 897.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4885 tasks      | elapsed: 1093.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5760 out of 5760 | elapsed: 1280.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'max_depth': [60, 70, 80, 90], 'max_features': ['auto', 6, 7, 8, 9, 10], 'min_samples_leaf': [1, 2, 3, 4], 'min_samples_split': [4, 5, 6, 7], 'n_estimators': [800, 1200, 1600, 1800, 2000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 8,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 1800}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_grid.predict(test_x)\n",
    "rmseGrid = metrics.mean_squared_error(predictions, test_y)**(1/2)\n",
    "r2Grid = metrics.r2_score(predictions, test_y)\n",
    "varGrid = metrics.explained_variance_score(predictions,test_y)\n",
    "pearsoncorrGrid = pearsonr(predictions, test_y)\n",
    "perrorGrid = abs(predictions - test_y)/test_y\n",
    "accuracyGrid = 1 - statistics.median(perrorGrid)\n",
    "errorGrid = abs(predictions - test_y)\n",
    "merrorGrid = errorGrid.mean()\n",
    "medErrorGrid = statistics.median(errorGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.0066008223\n",
      "r2: 0.832396931877\n",
      "var:0.832397958874\n",
      "pearsonCorr: (0.92545982565000462, 0.0)\n",
      "Accuracy: 0.843614455923\n",
      "Mean Error: 6.17400494897\n",
      "Median Error: 3.63263172399\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \" + str(rmseGrid))\n",
    "print(\"r2: \"+ str(r2Grid))\n",
    "print(\"var:\" + str(varGrid))\n",
    "print(\"pearsonCorr: \"+ str(pearsoncorrGrid))\n",
    "print(\"Accuracy: \" + str(accuracyGrid))\n",
    "print(\"Mean Error: \" + str(merrorGrid))\n",
    "print(\"Median Error: \" + str(medErrorGrid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight increase in accuracy but negligible effects across the board in most other categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cross validation\n",
    "Using the internal cross validation packages we can compute scores without worrying about over fitting or tuning hyper parameters to specific data sets. This can cause a pseudo leakage of our testing data into the training set. We will start the cross validation with the random forest regressor we got from the best estimator from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(bootstrap = True, max_depth = 50, max_features = 7, min_samples_leaf = 1, n_estimators = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf, RideWaits[keyFeatures], RideWaits[\"Wait\"], cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90298668,  0.80734268,  0.75187512,  0.70698203,  0.69998131,\n",
       "        0.6405473 ,  0.74681927,  0.60565567,  0.65903657,  0.74175662])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a single metric, it is perhaps more useful to obtain a number of metrics for each of our cross validated models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "def cross_validation_metrics(df,  target, folds, key_cols = None,):\n",
    "    df = df.dropna(how = 'any')\n",
    "    if key_cols is None:\n",
    "        X = df.drop(target, axis = 1)\n",
    "    else:\n",
    "        X = df[key_cols]\n",
    "    y = np.array(df[target])\n",
    "    overall_rmse = []\n",
    "    overall_accuracy = []\n",
    "    overall_median_error = []\n",
    "    overall_mean_error = []\n",
    "    overall_r2 = []\n",
    "    corr = []\n",
    "    kf = KFold(n_splits = folds)\n",
    "    i = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        rf = RandomForestRegressor(n_estimators = 1800,max_features = 'auto', min_samples_split = 4, min_samples_leaf = 1,max_depth = 60)\n",
    "        rf.fit(X_train, y_train)\n",
    "        predictions = rf.predict(X_test)\n",
    "        predictions = predictions[y_test>0]\n",
    "        y_test = y_test[y_test>0]\n",
    "        rmse = metrics.mean_squared_error(predictions, y_test)**(1/2)\n",
    "        var = metrics.explained_variance_score(predictions,y_test)\n",
    "        pearsoncorr = pearsonr(predictions, np.array(y_test))\n",
    "        perror = abs(predictions - y_test)/y_test\n",
    "        mperror = statistics.median(perror)\n",
    "        error = abs(predictions - y_test)\n",
    "        merror = error.mean()\n",
    "        print(\"Fold \" + str(i))\n",
    "        print(\"RMSE: \"+ str(rmse))\n",
    "        print(\"Correlation: \"+ str(pearsoncorr))\n",
    "        print(\"Accuracy: \" + str(1-mperror))\n",
    "        print(\"Mean Error: \"+ str(merror))\n",
    "        print(\"Median Error: \"+ str(statistics.median(error)))\n",
    "        print(\"-------------------------\")\n",
    "        overall_rmse.append(rmse)\n",
    "        overall_accuracy.append((1-mperror))\n",
    "        overall_median_error.append(statistics.median(error))\n",
    "        overall_mean_error.append(merror)\n",
    "        #overall_r2.append(r2)\n",
    "        corr.append(pearsoncorr[0])\n",
    "        i = i+1\n",
    "    \n",
    "    return_dict = {\n",
    "        'rmse': np.mean(overall_rmse),\n",
    "        'accuracy': np.mean(overall_accuracy),\n",
    "        'median_error': np.mean(overall_median_error),\n",
    "        'mean_error' : np.mean(overall_mean_error),\n",
    "        'correlation':np.mean(corr)\n",
    "    }\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "RMSE: 14.0864178617\n",
      "Correlation: (0.86070493846897367, 0.0)\n",
      "Accuracy: 0.780069050768\n",
      "Mean Error: 9.13943318343\n",
      "Median Error: 5.91366552814\n",
      "-------------------------\n",
      "Fold 2\n",
      "RMSE: 12.9697961772\n",
      "Correlation: (0.85963424951529277, 0.0)\n",
      "Accuracy: 0.755968130074\n",
      "Mean Error: 8.51465200521\n",
      "Median Error: 5.31448983886\n",
      "-------------------------\n",
      "Fold 3\n",
      "RMSE: 13.8485861617\n",
      "Correlation: (0.86092954216819595, 0.0)\n",
      "Accuracy: 0.753655610215\n",
      "Mean Error: 9.20421368691\n",
      "Median Error: 6.06492118607\n",
      "-------------------------\n",
      "Fold 4\n",
      "RMSE: 15.8409826146\n",
      "Correlation: (0.82451055033896337, 0.0)\n",
      "Accuracy: 0.715243255137\n",
      "Mean Error: 10.5407148401\n",
      "Median Error: 6.63212071108\n",
      "-------------------------\n",
      "Fold 5\n",
      "RMSE: 16.8469258534\n",
      "Correlation: (0.81033153672827551, 0.0)\n",
      "Accuracy: 0.697415474813\n",
      "Mean Error: 11.0487544193\n",
      "Median Error: 6.94941428171\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_metrics = cross_validation_metrics(RideWaits,\"Wait\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.74837470334065614,\n",
       " 'correlation': 0.85533009919381831,\n",
       " 'mean_error': 9.5353904779754295,\n",
       " 'median_error': 6.029964107991681,\n",
       " 'rmse': 14.430293128915924}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_frame = pd.DataFrame(list(model_metrics.items()), columns = ['Metric Name', 'Metric Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric Name</th>\n",
       "      <th>Metric Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rmse</td>\n",
       "      <td>14.430293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.748375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>median_error</td>\n",
       "      <td>6.029964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mean_error</td>\n",
       "      <td>9.535390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>correlation</td>\n",
       "      <td>0.855330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Metric Name  Metric Value\n",
       "0          rmse     14.430293\n",
       "1      accuracy      0.748375\n",
       "2  median_error      6.029964\n",
       "3    mean_error      9.535390\n",
       "4   correlation      0.855330"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
